# 3주차 weekly mission

- HashSet의 내부 동작 방식과 중복 제거 메커니즘을 설명하고, HashSet이 효율적인 중복 체크를 할 수 있는 이유를 설명해주세요.
- O(n)과 O(log n)의 성능 차이를 실생활 예시를 들어 설명하고, 데이터의 크기가 1백만 개일 때 각각 대략 몇 번의 연산이 필요한지 비교해주세요.

## 1. Hash Set

**Hash Set의 내부 동작 방식**
`HashSet` 은 Java에서 제공하는 `Set` 인터페이스의 구현체로, 내부적으로 `HashMap`을 사용하여 데이터를 저장합니다. `HashSet`은 요소의 중복을 허용하지 않으며, 빠른 검색 및 삽입 성능을 제공합니다.

### HashSet의 구조

- `HashSet`은 내부적으로 `HashMap`을 사용하여 데이터를 저장합니다.
- `HashMap`의 Key로 `HashSet`의 요소를 저장하고, value은 상수 객체로 설정됩니다.
- 내부적으로 `HashMap.put(key, PRESENT)`을 호출하여 데이터를 추가합니다.

```java
private static final Object PRESENT = new Object();
private transient HashMap<E, Object> map;

public HashSet() {
  map = new HashMap<>();
}

public boolean add(E e) {
  return map.put(e, PRESENT) == null;
}
```

- `put()` 메서드는 기존에 존재하는 키가 있을 경우 `null`을 반환하지 않기 때문에, 이를 통해 중복 여부를 판별할 수 있습니다.

### HashSet이 효율적인 중복 체크를 할 수 있는 이유

1. O(1)에 가까운 조회 속도

- `HashSet`은 내부적으로 `HashMap`을 사용하며, 해시 테이블을 기반으로 동작합니다.
- 일반적으로 `put()` 및 `contains()` 연산은 평균적으로 O(1) 시간 복잡도를 가집니다.
- 리스트에서 중복 체크는 O(N) (전체탐색)이지만, `HashSet`은 해시값을 사용하여 빠르게 중복을 탐색할 수 있습니다.

2. 해시 함수를 이용한 빠른 중복 검사

- 요소를 추가할 때 `hashCode()`를 먼저 검사하여 중복 여부를 빠르게 판단합니다.
- 동일한 해시값을 가지더라도 `equals()` 메서드로 최종 비교를 수행하며 정확한 중복판별을 합니다.
- 해쉬 테이블에 저장할 때 값도 함께 저장하여 비교하여 동일한지 검사합니다.

3. 체이닝 또는 트리 구조를 통한 충돌 해결

- 해시 충돌이 발생하면 Java 8부터는 `LinkedList` 대신 트리 구조를 사용하여 O(log N)으로 성능을 향상시켰습니다.
- 이는 충돌이 많은 경우에도 성능 저하를 줄이는데 도움을 줍니다.

### 결론

- `HashSet`은 내부적으로 `HashMap`을 사용하여 데이터를 저장하고, 요소를 `HashMap`의 키로 활용하여 중복을 효율적으로 검사합니다.
- `hashCode()`와 `equlas()` 메서드를 적절히 구현하면 `HashSet`은 평균 O(1)의 시간 복잡도로 중복 체크 및 삽입을 수행할 수 있습니다.
- 해시 충돌이 발생하면 `equlas()` 비교후 `체이닝`을 통해 저장하여 정확한 중복 제거가 가능합니다.

## 2. 연산 비교

### O(n) 과 O(log n)의 성능 차이 - 실생활 예시

알고리즘의 시간 복잡도를 실생활 예시로 설명하겠습니다.

1. O(n) - 선형 탐색

- 예시 : 도서관에서 특정 책을 찾으려면 책장을 처음부터 하나씩 확인해야한다고 가정합니다.
- 만약 책이 1_000권이라면 최악의 경우 1_000권을 모두 확인해야 합니다.

2. O(log n) - 이진 탐색

- 예시 : 전화번호부에서 특정 사람의 번호를 찾을 때, 전체를 다 읽지 않고 절반씩 줄여가며 찾습니다.
- 매번 절반으로 줄어들기 때문에 훨씬 빠르게 목표를 찾을 수 있습니다.

### O(n)과 O(log n)의 연산 횟수 비교

데이터 크기가 백만개라고 가정하고 각각의 연산 횟수를 비교
|데이터 개수(n) | O(n) 선형탐색 | O(log n) 이진탐색|
|--------------|-----------------|------------------|
|10|10|4|
|100|100|7|
|1_000|1_000|10|
|10_000|10_000|14|
|100_000|100_000|17|
|1_000_000|1_000_000|20|

### 결론

- O(n)은 데이터가 커질수록 연산 횟수가 선형적으로 증가합니다
- O(log n)은 데이터가 커져도 느리게 증가하며 훨씬 빠른 속도를 보장합니다.
- 예를 들어, HashSet과 ArrayList.containse() 의 중복 검사 성능 차이를 보면, HashSet이 훨씬 효율적인 이유를 알 수 있습니다.

즉, O(n)과 O(log n)의 차이는 작은 데이터에서는 크지 않지만, 데이터가 많아질수록 엄청난 성능 차이를 만들게 됩니다.
